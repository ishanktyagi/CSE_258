{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"homework1.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x231da025ba8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"homework1.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function for parsing JSONdata\n",
    "def parseData(fname):\n",
    "    for l in fname:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('beer_50000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and parsing JSONdata\n",
    "data  =list(parseData(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beer/ABV': 6.2,\n",
       " 'beer/beerId': '48213',\n",
       " 'beer/brewerId': '10325',\n",
       " 'beer/name': 'Red Moon',\n",
       " 'beer/style': 'English Strong Ale',\n",
       " 'review/appearance': 3.0,\n",
       " 'review/aroma': 2.5,\n",
       " 'review/overall': 3.0,\n",
       " 'review/palate': 3.0,\n",
       " 'review/taste': 3.0,\n",
       " 'review/text': 'Dark red color, light beige foam, average.\\tIn the smell malt and caramel, not really light.\\tAgain malt and caramel in the taste, not bad in the end.\\tMaybe a note of honey in teh back, and a light fruitiness.\\tAverage body.\\tIn the aftertaste a light bitterness, with the malt and red fruit.\\tNothing exceptional, but not bad, drinkable beer.',\n",
       " 'review/timeStruct': {'hour': 13,\n",
       "  'isdst': 0,\n",
       "  'mday': 1,\n",
       "  'min': 44,\n",
       "  'mon': 3,\n",
       "  'sec': 57,\n",
       "  'wday': 6,\n",
       "  'yday': 60,\n",
       "  'year': 2009},\n",
       " 'review/timeUnix': 1235915097,\n",
       " 'user/profileName': 'stcules'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tasks — Regression (week 1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.No of Reviews for each style of beer in the dataset (`beer/style`) ,  \n",
    "#  avg value of `review/taste` for reviews from each style  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgReview(data):\n",
    "    totalRev = dict()\n",
    "    revFreq = dict()\n",
    "    avgRev = dict()\n",
    "    for dict_ in data:\n",
    "        if dict_['beer/style'] not in totalRev:\n",
    "            totalRev[dict_['beer/style']] = 0\n",
    "            revFreq[dict_['beer/style']]  = 0\n",
    "            \n",
    "        totalRev[dict_['beer/style']] += dict_['review/taste']\n",
    "        revFreq [dict_['beer/style']] += 1\n",
    "    for style in totalRev:\n",
    "        avgRev[style] = round(totalRev[style]/revFreq[style], 6)\n",
    "    return avgRev, revFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRev ,revFreq = avgReview(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Altbier': 165,\n",
       " 'American Adjunct Lager': 242,\n",
       " 'American Amber / Red Ale': 665,\n",
       " 'American Amber / Red Lager': 42,\n",
       " 'American Barleywine': 825,\n",
       " 'American Black Ale': 138,\n",
       " 'American Blonde Ale': 357,\n",
       " 'American Brown Ale': 314,\n",
       " 'American Dark Wheat Ale': 14,\n",
       " 'American Double / Imperial IPA': 3886,\n",
       " 'American Double / Imperial Pilsner': 14,\n",
       " 'American Double / Imperial Stout': 5964,\n",
       " 'American IPA': 4113,\n",
       " 'American Malt Liquor': 90,\n",
       " 'American Pale Ale (APA)': 2288,\n",
       " 'American Pale Lager': 123,\n",
       " 'American Pale Wheat Ale': 154,\n",
       " 'American Porter': 2230,\n",
       " 'American Stout': 591,\n",
       " 'American Strong Ale': 166,\n",
       " 'American Wild Ale': 98,\n",
       " 'Baltic Porter': 514,\n",
       " 'Belgian Dark Ale': 175,\n",
       " 'Belgian IPA': 128,\n",
       " 'Belgian Pale Ale': 144,\n",
       " 'Belgian Strong Dark Ale': 146,\n",
       " 'Belgian Strong Pale Ale': 632,\n",
       " 'Berliner Weissbier': 10,\n",
       " 'BiÃ¨re de Garde': 7,\n",
       " 'Black & Tan': 122,\n",
       " 'Bock': 148,\n",
       " 'Braggot': 26,\n",
       " 'California Common / Steam Beer': 11,\n",
       " 'Chile Beer': 11,\n",
       " 'Cream Ale': 69,\n",
       " 'Czech Pilsener': 1501,\n",
       " 'Doppelbock': 873,\n",
       " 'Dortmunder / Export Lager': 31,\n",
       " 'Dubbel': 165,\n",
       " 'Dunkelweizen': 61,\n",
       " 'Eisbock': 8,\n",
       " 'English Barleywine': 133,\n",
       " 'English Bitter': 267,\n",
       " 'English Brown Ale': 495,\n",
       " 'English Dark Mild Ale': 21,\n",
       " 'English India Pale Ale (IPA)': 175,\n",
       " 'English Pale Ale': 1324,\n",
       " 'English Pale Mild Ale': 21,\n",
       " 'English Porter': 367,\n",
       " 'English Stout': 136,\n",
       " 'English Strong Ale': 164,\n",
       " 'Euro Dark Lager': 144,\n",
       " 'Euro Pale Lager': 701,\n",
       " 'Euro Strong Lager': 329,\n",
       " 'Extra Special / Strong Bitter (ESB)': 667,\n",
       " 'Flanders Oud Bruin': 13,\n",
       " 'Flanders Red Ale': 2,\n",
       " 'Foreign / Export Stout': 55,\n",
       " 'Fruit / Vegetable Beer': 1355,\n",
       " 'German Pilsener': 586,\n",
       " 'Hefeweizen': 618,\n",
       " 'Herbed / Spiced Beer': 73,\n",
       " 'Irish Dry Stout': 101,\n",
       " 'Irish Red Ale': 83,\n",
       " 'Keller Bier / Zwickel Bier': 23,\n",
       " 'Kristalweizen': 7,\n",
       " 'KÃ¶lsch': 94,\n",
       " 'Lambic - Fruit': 6,\n",
       " 'Lambic - Unblended': 10,\n",
       " 'Light Lager': 503,\n",
       " 'Low Alcohol Beer': 7,\n",
       " 'Maibock / Helles Bock': 225,\n",
       " 'Milk / Sweet Stout': 69,\n",
       " 'Munich Dunkel Lager': 141,\n",
       " 'Munich Helles Lager': 650,\n",
       " 'MÃ¤rzen / Oktoberfest': 557,\n",
       " 'Oatmeal Stout': 102,\n",
       " 'Old Ale': 1052,\n",
       " 'Pumpkin Ale': 560,\n",
       " 'Quadrupel (Quad)': 119,\n",
       " 'Rauchbier': 1938,\n",
       " 'Russian Imperial Stout': 2695,\n",
       " 'Rye Beer': 1798,\n",
       " 'Saison / Farmhouse Ale': 141,\n",
       " 'Schwarzbier': 53,\n",
       " 'Scotch Ale / Wee Heavy': 2776,\n",
       " 'Scottish Ale': 78,\n",
       " 'Scottish Gruit / Ancient Herbed Ale': 65,\n",
       " 'Smoked Beer': 61,\n",
       " 'Tripel': 257,\n",
       " 'Vienna Lager': 33,\n",
       " 'Weizenbock': 13,\n",
       " 'Wheatwine': 455,\n",
       " 'Winter Warmer': 259,\n",
       " 'Witbier': 162}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Altbier': 3.40303,\n",
       " 'American Adjunct Lager': 2.948347,\n",
       " 'American Amber / Red Ale': 3.513534,\n",
       " 'American Amber / Red Lager': 3.690476,\n",
       " 'American Barleywine': 4.064242,\n",
       " 'American Black Ale': 3.873188,\n",
       " 'American Blonde Ale': 3.254902,\n",
       " 'American Brown Ale': 3.743631,\n",
       " 'American Dark Wheat Ale': 3.678571,\n",
       " 'American Double / Imperial IPA': 4.033325,\n",
       " 'American Double / Imperial Pilsner': 3.821429,\n",
       " 'American Double / Imperial Stout': 4.479963,\n",
       " 'American IPA': 4.000851,\n",
       " 'American Malt Liquor': 2.255556,\n",
       " 'American Pale Ale (APA)': 3.649694,\n",
       " 'American Pale Lager': 3.215447,\n",
       " 'American Pale Wheat Ale': 3.334416,\n",
       " 'American Porter': 4.081839,\n",
       " 'American Stout': 3.819797,\n",
       " 'American Strong Ale': 3.569277,\n",
       " 'American Wild Ale': 4.188776,\n",
       " 'Baltic Porter': 4.213035,\n",
       " 'Belgian Dark Ale': 3.34,\n",
       " 'Belgian IPA': 3.949219,\n",
       " 'Belgian Pale Ale': 3.739583,\n",
       " 'Belgian Strong Dark Ale': 3.695205,\n",
       " 'Belgian Strong Pale Ale': 4.056171,\n",
       " 'Berliner Weissbier': 3.55,\n",
       " 'BiÃ¨re de Garde': 3.928571,\n",
       " 'Black & Tan': 3.942623,\n",
       " 'Bock': 3.189189,\n",
       " 'Braggot': 3.807692,\n",
       " 'California Common / Steam Beer': 3.318182,\n",
       " 'Chile Beer': 3.954545,\n",
       " 'Cream Ale': 3.028986,\n",
       " 'Czech Pilsener': 3.609594,\n",
       " 'Doppelbock': 3.982818,\n",
       " 'Dortmunder / Export Lager': 3.419355,\n",
       " 'Dubbel': 3.736364,\n",
       " 'Dunkelweizen': 3.491803,\n",
       " 'Eisbock': 3.75,\n",
       " 'English Barleywine': 4.360902,\n",
       " 'English Bitter': 3.537453,\n",
       " 'English Brown Ale': 3.728283,\n",
       " 'English Dark Mild Ale': 3.785714,\n",
       " 'English India Pale Ale (IPA)': 3.471429,\n",
       " 'English Pale Ale': 3.483761,\n",
       " 'English Pale Mild Ale': 3.595238,\n",
       " 'English Porter': 3.707084,\n",
       " 'English Stout': 3.599265,\n",
       " 'English Strong Ale': 3.756098,\n",
       " 'Euro Dark Lager': 3.704861,\n",
       " 'Euro Pale Lager': 2.96291,\n",
       " 'Euro Strong Lager': 2.848024,\n",
       " 'Extra Special / Strong Bitter (ESB)': 3.685157,\n",
       " 'Flanders Oud Bruin': 3.923077,\n",
       " 'Flanders Red Ale': 3.25,\n",
       " 'Foreign / Export Stout': 3.254545,\n",
       " 'Fruit / Vegetable Beer': 3.607749,\n",
       " 'German Pilsener': 3.667235,\n",
       " 'Hefeweizen': 3.635113,\n",
       " 'Herbed / Spiced Beer': 3.445205,\n",
       " 'Irish Dry Stout': 3.623762,\n",
       " 'Irish Red Ale': 2.981928,\n",
       " 'Keller Bier / Zwickel Bier': 3.869565,\n",
       " 'Kristalweizen': 2.785714,\n",
       " 'KÃ¶lsch': 3.696809,\n",
       " 'Lambic - Fruit': 3.75,\n",
       " 'Lambic - Unblended': 3.3,\n",
       " 'Light Lager': 2.39662,\n",
       " 'Low Alcohol Beer': 2.714286,\n",
       " 'Maibock / Helles Bock': 3.746667,\n",
       " 'Milk / Sweet Stout': 3.782609,\n",
       " 'Munich Dunkel Lager': 3.780142,\n",
       " 'Munich Helles Lager': 3.959231,\n",
       " 'MÃ¤rzen / Oktoberfest': 3.593357,\n",
       " 'Oatmeal Stout': 3.77451,\n",
       " 'Old Ale': 4.096008,\n",
       " 'Pumpkin Ale': 3.7875,\n",
       " 'Quadrupel (Quad)': 3.596639,\n",
       " 'Rauchbier': 4.067853,\n",
       " 'Russian Imperial Stout': 4.300371,\n",
       " 'Rye Beer': 4.213571,\n",
       " 'Saison / Farmhouse Ale': 3.702128,\n",
       " 'Schwarzbier': 3.622642,\n",
       " 'Scotch Ale / Wee Heavy': 4.083393,\n",
       " 'Scottish Ale': 3.762821,\n",
       " 'Scottish Gruit / Ancient Herbed Ale': 3.907692,\n",
       " 'Smoked Beer': 3.196721,\n",
       " 'Tripel': 3.784047,\n",
       " 'Vienna Lager': 3.530303,\n",
       " 'Weizenbock': 3.384615,\n",
       " 'Wheatwine': 4.186813,\n",
       " 'Winter Warmer': 3.621622,\n",
       " 'Witbier': 3.527778}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple predictor with a single binary feature indicating whether a beer is an `American IPA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFeature(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in data:\n",
    "        if d['beer/style'] == 'American IPA':\n",
    "            X.append([1, 1])\n",
    "        else:\n",
    "            X.append([1, 0])\n",
    "        y.append(d['review/taste'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = genFeature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Linear Regression using numpy OLS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, residuals, rank, s = np.linalg.lstsq(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9152047420838927, 0.08564621828574305)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[0], theta[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25650.80867309])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Linear Regression using sckit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficients:\t [0.08564622]\n",
      "intercept:\t 3.9152047420838145\n",
      "MSE :\t 0.5130161734617366\n",
      "r2_score :\t 0.0010782641230113743\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X[:, 1:], y)\n",
    "y_pred = reg.predict(X[:, 1:])\n",
    "\n",
    "print(\"coeficients:\\t\",reg.coef_)\n",
    "print(\"intercept:\\t\",reg.intercept_)\n",
    "print(\"MSE :\\t\",MSE(y, y_pred ))\n",
    "print(\"r2_score :\\t\",r2_score(y, y_pred ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theta[0] represent the y-intercept of regression line\n",
    "\n",
    "theta[1] represent the slope of regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Splitting the data into train-test sets , Finding MSE on training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:int(len(X)/2),1:], X[int(len(X)/2):,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:int(len(X)/2)], y[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Using normal equations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficients:  [0.05606027]\n",
      "intercept:  3.9043563922942206\n",
      "MSE on train set:  0.558107286558669\n",
      "MSE on test set:  0.46841005096664573\n",
      "r2_score on train set: 0.0004442931134949202\n",
      "r2_score on test set: 7.227980262203282e-05\n"
     ]
    }
   ],
   "source": [
    "# linear Regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"coeficients: \",reg.coef_)\n",
    "print(\"intercept: \",reg.intercept_)\n",
    "print(\"MSE on train set: \",MSE(y_train, reg.predict(X_train)) )\n",
    "print(\"MSE on test set: \",MSE(y_test, reg.predict(X_test)))\n",
    "print(\"r2_score on train set:\",r2_score(y_train, reg.predict(X_train)) )\n",
    "print(\"r2_score on test set:\",r2_score(y_test, reg.predict(X_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extending the above model , incorporating binary features for every style of beer with ≥ 50 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFeatures(data, revFreq):\n",
    "    beer_rev50 = []\n",
    "    for beer_style in revFreq.keys():\n",
    "        if revFreq[beer_style] > 50:\n",
    "            beer_rev50.append(beer_style)\n",
    "\n",
    "    #print( \"beer styles with reviews count > 50 are :\",len(beer_rev50))\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in data:\n",
    "        x = []\n",
    "        for beer in beer_rev50:\n",
    "            x.append( d['beer/style'] == beer )\n",
    "        X.append(x)\n",
    "        y.append(d['review/taste'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = genFeatures(data, revFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 74), (50000,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:int(len(X)/2),:], X[int(len(X)/2):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:int(len(X)/2)], y[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Multiple Linear Regression Using scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficients:  [ 0.71136364  0.09815076  0.12193999 -0.4664673   0.02739474  0.12395105\n",
      "  0.22651515 -0.0058248  -0.2937747   0.01699134 -0.50681818  0.58195733\n",
      "  0.76540404 -0.83277972  0.14466111  0.11433566  0.39318182  0.26818182\n",
      "  0.25681818 -0.92019846 -0.02450111  0.69564175 -0.1798951   0.26709486\n",
      " -0.10223103  0.01818182  0.45638407 -0.58598485  0.10049889 -0.13106061\n",
      " -0.45410882  0.38356643  0.33596789  0.48544372  0.3763751  -0.65227273\n",
      "  0.44318182 -0.35681818  0.35359848  0.60472028 -0.09003966 -0.22045455\n",
      " -0.17824675  0.26761104 -0.11634199  0.1527972   0.16385851 -0.41285266\n",
      "  0.03420746  0.19621212  0.33580477 -0.74318182  0.20312334  0.8416167\n",
      " -0.10681818 -0.73802386 -0.18884943 -0.63806818  0.13786267  0.05895722\n",
      "  0.3305986   0.12651515 -0.31931818 -1.00681818  0.20984848  0.65508658\n",
      " -0.20681818 -0.38622995  0.46842454  0.11320382  0.3449362  -0.27061129\n",
      " -0.62765152 -1.23390152]\n",
      "intercept:  3.606818181818188\n",
      "MSE on training set:  0.3678402770901444\n",
      "MSE on testing set:  0.4336695104199656\n",
      "r2_score on train set: 0.3412075831238651\n",
      "r2_score on test set: 0.07423385988737574\n"
     ]
    }
   ],
   "source": [
    "# linear Regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"coeficients: \",reg.coef_)\n",
    "print(\"intercept: \",reg.intercept_)\n",
    "\n",
    "print(\"MSE on training set: \",MSE(y_train, reg.predict(X_train)) )\n",
    "print(\"MSE on testing set: \",MSE(y_test, reg.predict(X_test)) )\n",
    "\n",
    "print(\"r2_score on train set:\",r2_score(y_train, reg.predict(X_train)) )\n",
    "print(\"r2_score on test set:\",r2_score(y_test, reg.predict(X_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks — Classification (week 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. A predictor that estimates whether a beer is an `American IPA` using two features:\n",
    "[`beer/ABV`,`review/taste`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ABV_taste(datum):\n",
    "    return [1, datum['beer/ABV'], datum['review/taste']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_ABV_taste(d) for d in data]\n",
    "y = [d['beer/style'] == 'American IPA' for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:int(len(X)/2)], X[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:int(len(y)/2)], y[int(len(y)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score :  0.9226\n",
      "confusion matrix :\n",
      " [[22594   246]\n",
      " [ 1689   471]]\n",
      "classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.99      0.96     22840\n",
      "       True       0.66      0.22      0.33      2160\n",
      "\n",
      "avg / total       0.91      0.92      0.90     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_pred )\n",
    "print(\"Train set accuracy score : \", train_acc )\n",
    "print(\"confusion matrix :\\n\", confusion_matrix(y_train, y_pred))\n",
    "print(\"classification report :\\n\",classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score : 0.85632\n",
      "confusion matrix : \n",
      " [[21364  1683]\n",
      " [ 1909    44]]\n",
      "classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.93      0.92     23047\n",
      "       True       0.03      0.02      0.02      1953\n",
      "\n",
      "avg / total       0.85      0.86      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test set accuracy score :\", test_acc )\n",
    "print(\"confusion matrix : \\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report :\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Engineering using common words in `review/text` of   `American IPA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "textRevAmericanIPA = []\n",
    "for d in data:\n",
    "    if d['beer/style'] == 'American IPA':\n",
    "        textRevAmericanIPA.append(d['review/text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = []\n",
    "for text in textRevAmericanIPA:\n",
    "    tokens += tokenizer.tokenize(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "all_words = [w for w in tokens if not w in stop_words and len(w) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hops', 4686),\n",
       " ('head', 3942),\n",
       " ('The', 3872),\n",
       " ('beer', 3804),\n",
       " ('IPA', 3663),\n",
       " ('hop', 3343),\n",
       " ('malt', 3117),\n",
       " ('nice', 2959),\n",
       " ('citrus', 2865),\n",
       " ('good', 2613),\n",
       " ('one', 2040),\n",
       " ('orange', 1916),\n",
       " ('like', 1916),\n",
       " ('white', 1876),\n",
       " ('carbonation', 1825),\n",
       " ('color', 1799),\n",
       " ('glass', 1799),\n",
       " ('taste', 1772),\n",
       " ('This', 1760),\n",
       " ('grapefruit', 1754),\n",
       " ('well', 1745),\n",
       " ('bitterness', 1734),\n",
       " ('pine', 1700),\n",
       " ('bitter', 1695),\n",
       " ('bit', 1690),\n",
       " ('flavor', 1684),\n",
       " ('lacing', 1660),\n",
       " ('light', 1660),\n",
       " ('finish', 1543),\n",
       " ('aroma', 1541),\n",
       " ('sweet', 1508),\n",
       " ('little', 1448),\n",
       " ('amber', 1339),\n",
       " ('caramel', 1319),\n",
       " ('body', 1292),\n",
       " ('Very', 1235),\n",
       " ('medium', 1179),\n",
       " ('bottle', 1151),\n",
       " ('Pours', 1141),\n",
       " ('floral', 1132),\n",
       " ('hoppy', 1102),\n",
       " ('great', 1048),\n",
       " ('nose', 1044),\n",
       " ('really', 1036),\n",
       " ('balanced', 1029),\n",
       " ('notes', 1014),\n",
       " ('smell', 951),\n",
       " ('dry', 926),\n",
       " ('fresh', 915),\n",
       " ('would', 909)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat = ['citrus', 'IPA', 'bitter', 'grapefruit','caramel']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customFeatures(datum):\n",
    "    return [1, \n",
    "            datum['beer/ABV'],\n",
    "           'citrus' in datum['review/text'],\n",
    "           'IPA' in datum['review/text'],\n",
    "           'bitter' in datum['review/text'],\n",
    "           'grapefruit' in datum['review/text'],\n",
    "           'caramel' in datum['review/text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [customFeatures(d) for d in data]\n",
    "y = [d['beer/style'] == 'American IPA' for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:int(len(X)/2)], X[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:int(len(X)/2)], y[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = svm.SVC(C=1000)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy score :  0.96248\n",
      "confusion matrix :\n",
      " [[22353   487]\n",
      " [  451  1709]]\n",
      "classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.98      0.98     22840\n",
      "       True       0.78      0.79      0.78      2160\n",
      "\n",
      "avg / total       0.96      0.96      0.96     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_pred )\n",
    "\n",
    "print(\"Train set accuracy score : \", train_acc )\n",
    "print(\"confusion matrix :\\n\", confusion_matrix(y_train, y_pred))\n",
    "print(\"classification report :\\n\",classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score : 0.9262\n",
      "confusion matrix : \n",
      " [[21729  1318]\n",
      " [  527  1426]]\n",
      "classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.94      0.96     23047\n",
      "       True       0.52      0.73      0.61      1953\n",
      "\n",
      "avg / total       0.94      0.93      0.93     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test set accuracy score :\", test_acc )\n",
    "print(\"confusion matrix : \\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report :\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Effect  of  regularization  constant C  on SVM  performance \n",
    "  C\n",
    "∈ [0.1,10,1000,100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C :  0.1 \t train set accuracy :  0.95192 \ttest set accuracy :  0.9448 \n",
      "\n",
      "C :  10 \t train set accuracy :  0.96176 \ttest set accuracy :  0.93616 \n",
      "\n",
      "C :  1000 \t train set accuracy :  0.96248 \ttest set accuracy :  0.9262 \n",
      "\n",
      "C :  100000 \t train set accuracy :  0.9644 \ttest set accuracy :  0.92496 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.1, 10, 1000, 100000 ]:\n",
    "    clf3 = svm.SVC(C=c)\n",
    "    clf3.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf3.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_pred)\n",
    "    \n",
    "    y_pred = clf3.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"C : \", c,'\\t', \"train set accuracy : \", train_acc,\"\\ttest set accuracy : \", test_acc,\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature_ABV_taste(d) for d in data]\n",
    "y = [d['beer/style'] == 'American IPA' for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:int(len(X)/2)], X[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:int(len(X)/2)], y[int(len(X)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeTheta(X):\n",
    "    n_coeff = X.shape[1]\n",
    "    return np.zeros(n_coeff)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "def costFun(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    z = np.dot(X, theta)\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    return (-1/m)*( np.sum( y * np.log(h) + (1 - y) * np.log (1 - h) ) )\n",
    "\n",
    "def cal_gradient(X, y, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    h = sigmoid(z)\n",
    "    return np.dot( X.T, (h - y) ) / len(y)\n",
    "\n",
    "def perform_logisticReg(X, y, lr=0.01, num_itr=100001):\n",
    "    theta = initializeTheta(X)\n",
    "    for i in range(num_itr):\n",
    "        gradient = cal_gradient(X, y, theta)\n",
    "        theta -= lr * gradient\n",
    "        if( i % 10000 == 0):\n",
    "            print(\"Loss  :{}\\n\".format(costFun(X, y, theta)))\n",
    "    return theta\n",
    "\n",
    "def predict_logisticReg(theta, X):\n",
    "    z = np.dot(X, theta) \n",
    "    h = sigmoid(z)\n",
    "    y_pred = np.round(h + 0.1)\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    correct_pred =[ act == pred for act, pred in zip(y_test, y_pred)] \n",
    "    accuracy =  np.sum(correct_pred) * 1.0 / len(correct_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  :0.5671449053246294\n",
      "\n",
      "Loss  :0.27006366173259144\n",
      "\n",
      "Loss  :0.26909583942386867\n",
      "\n",
      "Loss  :0.2685040375639266\n",
      "\n",
      "Loss  :0.2681354550899628\n",
      "\n",
      "Loss  :0.26790255770082716\n",
      "\n",
      "Loss  :0.26775371057680347\n",
      "\n",
      "Loss  :0.2676577193019152\n",
      "\n",
      "Loss  :0.26759536926394356\n",
      "\n",
      "Loss  :0.26755463794585554\n",
      "\n",
      "Loss  :0.26752790701431667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta = perform_logisticReg(X_train, y_train, lr=0.01, num_itr=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta : [-1.62445469 -0.45498184  0.63841396]\n"
     ]
    }
   ],
   "source": [
    "print(\"theta : {}\".format(theta) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy :  0.91272\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logisticReg(theta, X_train)\n",
    "print(\"train set accuracy : \", accuracy(y_train, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy :  0.9208\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_logisticReg(theta, X_test)\n",
    "\n",
    "print(\"test set accuracy : \", accuracy(y_test, y_pred) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
